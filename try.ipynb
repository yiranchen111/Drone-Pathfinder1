{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cee9535c-4c6c-4693-bccd-ce9e9253c35e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/biewen/Desktop/myenv/share/images/output_path_image-08.jpeg\n",
            "output_path_image-08.jpeg  output: \n",
            " Step 1: Begin your flight near the cluster of taller buildings with red brick facades and large windows. These buildings are surrounded by streets on all sides, providing a clear area for takeoff.\n",
            "Step 2: Proceed towards the area with a mix of both red and beige buildings, maintaining a steady altitude to capture the architectural diversity. These buildings are medium in height compared to the starting point.\n",
            "Step 3: Continue the flight path passing over a street that intersects with several others. This area features a variety of building materials, including glass and concrete, which contrast with the earlier brick structures.\n",
            "Step 4: Navigate towards a section where the buildings are predominantly lower in height. This area provides a different perspective, showcasing smaller structures amidst the urban environment.\n",
            "Step 5: Pause briefly above an open space that appears to be a small parking area or courtyard, surrounded by buildings. This will allow for detailed aerial shots of the urban layout and building entrances.\n",
            "Step 6: Conclude the flight by gradually moving towards the edge of the dense building area, where the structures begin to spread out, indicating a transition to a less densely populated urban zone. This final segment offers a view of how the city's architecture disperses into the surrounding environment.\n",
            "This route covers a short to moderate distance, focusing on urban architectural elements and the layout of streets and buildings.\n",
            "/Users/biewen/Desktop/Drone_Path_Guidance/myenv/share/images/output_path_image-04.jpeg\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m     image_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# print(image_url)\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     instructions \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_instructions\u001b[49m(\u001b[49mimage_url\u001b[49m)\n",
            "File \u001b[0;32m~/Desktop/Drone_Path_Guidance/myenv/lib/python3.10/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0m(*args, **kwargs)\n\u001b[273\u001b[0m             msg =f\"Missing required argument: {quote(missing[0])}\""
          ]
        }
      ],
      "source": [
        "import base64\n",
        "import torch\n",
        "from PIL import Image\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import io\n",
        "from PIL import Image \n",
        "import pandas as pd\n",
        "\n",
        "def encode_image_to_base64(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((512,512))\n",
        "    buffered = io.BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")  \n",
        "    image_b64=base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "    try:\n",
        "        decode_img=base64.b64decode(image_b64)\n",
        "    except base64.binascii.Error:\n",
        "        return False\n",
        "    return image_b64\n",
        "def generate_instructions(image_url):\n",
        "    try:\n",
        "        client = OpenAI(\n",
        "            api_key=\"\",  \n",
        "            base_url=\"https://api.openai.com/v1\"\n",
        "        )\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\"url\": image_url}, \n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": ('''This is an image taken by a drone, showing marked waypoints for the drone's flight path. \n",
        "                            Based on the actual scene, provide flight guidance text that includes details about objects, \n",
        "                            location, edges, attributes (color, material, accessories, etc.), distance \n",
        "                            (e.g., 'long-distance flight' or 'short-distance flight'), and where to pause.\n",
        "                            Format the output as Step 1, Step 2, ..., Step n. Avoid directional instructions \n",
        "                            (such as 'fly upwards') and do not mention red circles or blue lines.\n",
        "                            Ensure the response is in English. Do not use directional terms or refer to points or lines not part of the scene.\n",
        "                            ''')\n",
        "                        },\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "        )\n",
        "        return completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred while generating instructions: {str(e)}\"\n",
        "image_dir=\"./images/\"\n",
        "df=pd.read_excel(\"./output.xlsx\")\n",
        "df=df.drop(index=df.index)\n",
        "i=0\n",
        "for item in os.listdir(image_dir):\n",
        "    image_path=os.getcwd()+\"/images/\"+item\n",
        "    print(image_path)\n",
        "    image_base64=encode_image_to_base64(image_path)\n",
        "    if image_base64:\n",
        "        image_url=f\"data:image/png;base64,{image_base64}\"\n",
        "        instructions = generate_instructions(image_url)\n",
        "        row=pd.DataFrame({\"index\":i,\"image_name\":[item],\"output_instructions\":[instructions]})\n",
        "    else:\n",
        "        row=pd.DataFrame({\"index\":i,\"image_name\":[item],\"output_instructions\":[]})\n",
        "    i+=1\n",
        "    df = pd.concat([df,row],ignore_index=True)\n",
        "    df.to_excel(\"./output.xlsx\",index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

